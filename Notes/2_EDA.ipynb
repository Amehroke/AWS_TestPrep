{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\">Exploratory Data Analysis</h1>\n",
    "<h3 align=\"center\">Analyzing and visualizing data in AWS</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Reqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To start off what needs to be known for EDA\n",
    "\n",
    "1. **Python** - But the test will not test your Python knowledge.\n",
    "2. **Scikit_learn** Python library for machine learning models\n",
    "\n",
    "#### Types of Data:\n",
    "- Numerical\n",
    "- Categorical\n",
    "- Ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. A Probability Density Function (PDF) \n",
    "\n",
    "<h4 align=\"center\">Represents the probability distribution of a continuous random variable. Gives the likelihood (density) that the variable falls within a given range.</h4>\n",
    "<img src=\"../Figures/EDA/PDF.png\" style=\"width:400px; display:block; margin:auto;\">\n",
    "\n",
    "\n",
    "#### 2. A Probability Mass Function (PMF) \n",
    "<h4 align=\"center\">Gives the exact probability of a discrete random variable taking on a specific value. NOT CONTINOUS</h4>\n",
    "<img src=\"../Figures/EDA/PMF.png\" style=\"width:400px; display:block; margin:auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Poisson Distribution** is another Example of a PMF it works with discrete values. We cant sell 1/2 of a car, so PMF is a distribution we will use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality (repeating patterns over time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Seasonality is looking at a period in the data set that presents a repetative pattern.</h2>\n",
    "<img src=\"../Figures/EDA/Seasonality.png\" style=\"width:400px; display:block; margin:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend (long-term movement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">Trends is looking at the entire data set to see a upward or downward trend.</h2>\n",
    "<p align=\"center\">In this Example the trend is upward</p>\n",
    "<img src=\"../Figures/EDA/Trends.png\" style=\"width:400px; display:block; margin:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset - Sesonality = Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">If we calculate the seasonality and subtract it from the entire dataset it will give us the smooth line trend of the data</h3>\n",
    "<p align=\"center\">In this Example we subtract the sesonality from the dataset to get the smooth trend curve</p>\n",
    "<img src=\"../Figures/EDA/TrendSeason.png\" style=\"width:400px; display:block; margin:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series data consists of **trend**, **seasonality**, and **noise**. \n",
    "\n",
    "- Use an **additive model** when seasonal effects stay constant over time (e.g., sales increase by a fixed amount each year).\n",
    "- Use a **multiplicative model** when seasonality scales with the trend (e.g., sales double during holidays as the business grows).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Athena (Serverless)(Near-RealTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "AWS Athena is a serverless, interactive query service that allows you to run SQL queries on data stored in Amazon S3 without needing to set up or manage databases or servers.\n",
    "\n",
    "**Use Case:** when you have large datasets in S3 and need quick SQL queries without managing a database.\n",
    "\n",
    " **Cost Breakdown ðŸ’°**\n",
    "- **Pay-as-you-go**: No upfront costs, pay only for queries run.\n",
    "- **$5 per TB scanned**: Charges are based on the amount of data scanned by queries.\n",
    "\n",
    " **Ways to Reduce Costs ðŸ’¡**\n",
    "- **Use columnar storage formats** (e.g., **ORC, Parquet**).\n",
    "  - Improves query performance.\n",
    "- **Partition and compress data** to optimize query efficiency.\n",
    "\n",
    "- **AWS Glue** (for data cataloging) and **Amazon S3** (for data storage) have their **own separate charges**.\n",
    "\n",
    "ðŸ”¹ **Tip:** Optimize your data storage strategy to minimize the data scanned and reduce costs!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS QuickSight (Serverless)(Visualization of Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An application that helps generate visualizations and business insights from large datasets efficiently.\n",
    "\n",
    "Machine Learning Capabilites:\n",
    "- Anomaly detection\n",
    "- Forecasting\n",
    "- Auto-narratives\n",
    "\n",
    "### QuickSight Visual Types\n",
    "\n",
    "AutoGraph: based on the properties on the data gentrates a graph associated to the data, but is not always right. \n",
    "\n",
    "Bar Charts\n",
    "- For comparison and distribution (histograms)\n",
    "\n",
    "Line graphs\n",
    "- For changes over time\n",
    "\n",
    "Scatter plots, heat maps\n",
    "- For correlation\n",
    "\n",
    "Pie graphs, tree maps\n",
    "- For aggregation\n",
    "\n",
    "Pivot tables\n",
    "- For tabular data\n",
    "\n",
    "### **Know which charts are for which dataset, might be a question on the test**\n",
    "### Example: Based on this data what is the best visualization for it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Elastic Map Reduce (EMR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazon EMR (Elastic MapReduce)** is a managed big data platform that allows you to run Apache Spark, Hadoop, Presto, Hive, and other big data frameworks at scale on AWS. It is designed for processing large-scale datasets across a distributed computing environment.\n",
    "\n",
    "It is designed for processing **massive datasets**, making it easier to **prepare, normalize, and scale** data before feeding it into machine learning algorithms. \n",
    "\n",
    "### ðŸ’¡ Spark is usually preferred over Hadoop for new projects because it's faster and supports real-time processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMR Cluster Architecture & Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 align=\"center\">Represents the default Architecture of EMR, core and task nodes can be added to make the Architecture bigger. Also you can run mutilple different EMR clusters for different tasks</h4>\n",
    "<img src=\"../Figures/EDA/EMRArch.png\" style=\"width:600px; display:block; margin:auto;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark ML Lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What is Spark MLlib**\n",
    "A key advantage of Spark MLlib is that it enables **Common ML algorithms to run on distributed computing clusters**. In contrast, libraries like **Scikit-Learn** are designed for single-node execution and do not natively support distributed computing.\n",
    "\n",
    "### **ðŸš€ Machine Learning Algorithms in Spark MLlib**\n",
    "Spark MLlib provides a variety of machine learning models optimized for large-scale data processing:\n",
    "\n",
    "- **Classification**: Logistic Regression, NaÃ¯ve Bayes  \n",
    "- **Regression**: Linear and Non-Linear Regression Models  \n",
    "- **Decision Trees**: Random Forest, Gradient-Boosted Trees  \n",
    "- **Recommendation Systems**: Alternating Least Squares (ALS)  \n",
    "- **Clustering**: K-Means  \n",
    "- **Topic Modeling**: Latent Dirichlet Allocation (LDA)  \n",
    "- **ML Workflow Utilities**: Pipelines, Feature Transformation, Model Persistence  \n",
    "- **Dimensionality Reduction**: Singular Value Decomposition (SVD), Principal Component Analysis (PCA)  \n",
    "- **Statistics**: Summary Statistics, Hypothesis Testing  \n",
    "\n",
    "ðŸ’¡ **Key Takeaway**: If you need scalable machine learning for **big data**, Spark MLlib is a better choice than traditional libraries like **Scikit-Learn**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WorkFlow for EMR Model training\n",
    "\n",
    "#### âœ… Spark on Core Nodes â†’ Handles distributed data preprocessing & ETL across multiple machines.\n",
    "\n",
    "#### âœ… PyTorch on Task Nodes â†’ Performs matrix multiplications & model training using available hardware (CPU or GPU).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **What is Feature Engineering?**\n",
    "Feature engineering is the process of **transforming raw data into meaningful inputs** that improve machine learning model performance. It involves **selecting, creating, and modifying features** to highlight patterns in data. Common techniques include **normalization, one-hot encoding, feature scaling, dimensionality reduction (PCA), and interaction terms**. Good feature engineering enhances model accuracy by making important patterns more detectable. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Example:** Say we have a Person, their features could include height, age, money he makes, education etc. \n",
    "There are 100s 10000s of features we can create, but feature engineering is deciding which ones are the most important, if we dont have enough features how can we create more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curse of Dimensionality\n",
    "**The Curse of Dimensionality** refers to the problem where adding more features (dimensions) makes data sparser, increasing computation time and reducing model performance. When we add too many feature vectors, our data moves into a higher-dimensional space. This increases the possible solutions, making the data more sparse, meaning points are farther apart. As a result, models struggle to find meaningful patterns, leading to overfitting and poor generalization. **This is known as the Curse of Dimensionality.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Common Feature Engineering Techniques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding\n",
    "One-hot encoding is a method used to convert categorical variables into a binary matrix. Our dataset has some columns filled with words such as gender, education, and cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " City  Education  Gender\n",
      "    0          1       0\n",
      "    1          0       0\n",
      "    0          0       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "features = ['Education', 'City', 'Gender']\n",
    "## Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(features,dtype=int)\n",
    "\n",
    "print(df_encoded.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, **One-Hot Encoding** transforms categorical labels into **binary vectors**:  \n",
    "- **Education** â†’ `010`  \n",
    "- **City** â†’ `100`  \n",
    "- **Gender** â†’ `0001`  \n",
    "\n",
    "Each category is represented as a **unique binary vector**. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
